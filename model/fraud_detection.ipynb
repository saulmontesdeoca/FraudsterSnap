{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model for HackMX NDS Cognitive Labs Challenge\n",
    "## Fraud Detection\n",
    "#### Dataset obtained from IEEE-CIS Fraud Detection in Kaggle: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = \"data/train_identity.csv\"\n",
    "train_transaction = \"data/train_transaction.csv\"\n",
    "test_identity = \"data/test_identity.csv\"\n",
    "test_transaction = \"data/test_transaction.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 29.4 s, sys: 4.89 s, total: 34.3 s\nWall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time # visualize time to load data\n",
    "train_id = pd.read_csv(train_identity)\n",
    "train_tr = pd.read_csv(train_transaction)\n",
    "test_id = pd.read_csv(test_identity)\n",
    "test_tr = pd.read_csv(test_transaction)"
   ]
  },
  {
   "source": [
    "#### Downcasts types to reduce memory and optimize usage."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    _start = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    _end = df.memory_usage(deep=True).sum() / 1024 ** 2\n",
    "    saved = (_start - _end) / _start * 100\n",
    "    print(f\"Saved {saved:.2f}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved 8.32%\n",
      "Saved 40.53%\n",
      "Saved 8.38%\n",
      "Saved 40.20%\n"
     ]
    }
   ],
   "source": [
    "train_id = downcast_dtypes(train_id)\n",
    "train_tr = downcast_dtypes(train_tr)\n",
    "test_id = downcast_dtypes(test_id)\n",
    "test_tr = downcast_dtypes(test_tr)"
   ]
  },
  {
   "source": [
    "### Joining train tables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(\n",
    "    train_tr, train_id, how=\"left\", on=\"TransactionID\", left_index=True, right_index=True,\n",
    ")"
   ]
  },
  {
   "source": [
    "### Joining test tables as well"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(\n",
    "    test_tr, test_id, how=\"left\", on=\"TransactionID\", left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "source": [
    "### Taking a glimpse of how these tables look"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train shape: (590540, 434), Test shape: (506691, 433)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")"
   ]
  },
  {
   "source": [
    "### We think these are the features of the model to build"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = [\n",
    "    \"TransactionAmt\",\n",
    "    \"ProductCD\",\n",
    "    \"card1\",\n",
    "    \"card2\",\n",
    "    \"card3\",\n",
    "    \"card5\",\n",
    "    \"card6\",\n",
    "    \"addr1\",\n",
    "    \"addr2\",\n",
    "    \"dist1\",\n",
    "    \"dist2\",\n",
    "    \"P_emaildomain\",\n",
    "    \"R_emaildomain\",\n",
    "    \"C1\",\n",
    "    \"C2\",\n",
    "    \"C4\",\n",
    "    \"C5\",\n",
    "    \"C6\",\n",
    "    \"C7\",\n",
    "    \"C8\",\n",
    "    \"C9\",\n",
    "    \"C10\",\n",
    "    \"C11\",\n",
    "    \"C12\",\n",
    "    \"C13\",\n",
    "    \"C14\",\n",
    "    \"D1\",\n",
    "    \"D2\",\n",
    "    \"D3\",\n",
    "    \"D4\",\n",
    "    \"D5\",\n",
    "    \"D10\",\n",
    "    \"D11\",\n",
    "    \"D15\",\n",
    "    \"M1\",\n",
    "    \"M2\",\n",
    "    \"M3\",\n",
    "    \"M4\",\n",
    "    \"M6\",\n",
    "    \"M7\",\n",
    "    \"M8\",\n",
    "    \"M9\",\n",
    "    \"V1\",\n",
    "    \"V3\",\n",
    "    \"V4\",\n",
    "    \"V6\",\n",
    "    \"V8\",\n",
    "    \"V11\",\n",
    "    \"V13\",\n",
    "    \"V14\",\n",
    "    \"V17\",\n",
    "    \"V20\",\n",
    "    \"V23\",\n",
    "    \"V26\",\n",
    "    \"V27\",\n",
    "    \"V30\",\n",
    "    \"V36\",\n",
    "    \"V37\",\n",
    "    \"V40\",\n",
    "    \"V41\",\n",
    "    \"V44\",\n",
    "    \"V47\",\n",
    "    \"V48\",\n",
    "    \"V54\",\n",
    "    \"V56\",\n",
    "    \"V59\",\n",
    "    \"V62\",\n",
    "    \"V65\",\n",
    "    \"V67\",\n",
    "    \"V68\",\n",
    "    \"V70\",\n",
    "    \"V76\",\n",
    "    \"V78\",\n",
    "    \"V80\",\n",
    "    \"V82\",\n",
    "    \"V86\",\n",
    "    \"V88\",\n",
    "    \"V89\",\n",
    "    \"V91\",\n",
    "    \"V107\",\n",
    "    \"V108\",\n",
    "    \"V111\",\n",
    "    \"V115\",\n",
    "    \"V117\",\n",
    "    \"V120\",\n",
    "    \"V121\",\n",
    "    \"V123\",\n",
    "    \"V124\",\n",
    "    \"V127\",\n",
    "    \"V129\",\n",
    "    \"V130\",\n",
    "    \"V136\",\n",
    "    \"V138\",\n",
    "    \"V139\",\n",
    "    \"V142\",\n",
    "    \"V147\",\n",
    "    \"V156\",\n",
    "    \"V160\",\n",
    "    \"V162\",\n",
    "    \"V165\",\n",
    "    \"V166\",\n",
    "    \"V169\",\n",
    "    \"V171\",\n",
    "    \"V173\",\n",
    "    \"V175\",\n",
    "    \"V176\",\n",
    "    \"V178\",\n",
    "    \"V180\",\n",
    "    \"V182\",\n",
    "    \"V185\",\n",
    "    \"V187\",\n",
    "    \"V188\",\n",
    "    \"V198\",\n",
    "    \"V203\",\n",
    "    \"V205\",\n",
    "    \"V207\",\n",
    "    \"V209\",\n",
    "    \"V210\",\n",
    "    \"V215\",\n",
    "    \"V218\",\n",
    "    \"V220\",\n",
    "    \"V221\",\n",
    "    \"V223\",\n",
    "    \"V224\",\n",
    "    \"V226\",\n",
    "    \"V228\",\n",
    "    \"V229\",\n",
    "    \"V234\",\n",
    "    \"V235\",\n",
    "    \"V238\",\n",
    "    \"V240\",\n",
    "    \"V250\",\n",
    "    \"V252\",\n",
    "    \"V253\",\n",
    "    \"V257\",\n",
    "    \"V258\",\n",
    "    \"V260\",\n",
    "    \"V261\",\n",
    "    \"V264\",\n",
    "    \"V266\",\n",
    "    \"V267\",\n",
    "    \"V271\",\n",
    "    \"V274\",\n",
    "    \"V277\",\n",
    "    \"V281\",\n",
    "    \"V283\",\n",
    "    \"V284\",\n",
    "    \"V285\",\n",
    "    \"V286\",\n",
    "    \"V289\",\n",
    "    \"V291\",\n",
    "    \"V294\",\n",
    "    \"V296\",\n",
    "    \"V297\",\n",
    "    \"V301\",\n",
    "    \"V303\",\n",
    "    \"V305\",\n",
    "    \"V307\",\n",
    "    \"V309\",\n",
    "    \"V310\",\n",
    "    \"V314\",\n",
    "    \"V320\",\n",
    "    \"DeviceType\",\n",
    "    \"DeviceInfo\",\n",
    "    \"isFraud\", ]"
   ]
  },
  {
   "source": [
    "### Lets drop everything we are not using"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_train = [col for col in train.columns if col not in imp_features]\n",
    "cols_to_drop_test = [col for col in test.columns if col not in imp_features]\n",
    "\n",
    "train = train.drop(cols_to_drop_train, axis=1)\n",
    "test = test.drop(cols_to_drop_test, axis=1)"
   ]
  },
  {
   "source": [
    "### We need to replace all infinite values with 0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if train[col].dtype == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(590540, 165)\n(506691, 164)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"isFraud\", axis=1).copy()\n",
    "X_test = test.copy()\n",
    "y_train = train[\"isFraud\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(590540, 164) (506691, 164) (590540,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=7\n",
    ")"
   ]
  },
  {
   "source": [
    "### We are going to try out a RandomForest model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    max_depth=45, max_features=30, n_estimators=500, n_jobs=-1, min_samples_leaf=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1h 18min 27s, sys: 55.2 s, total: 1h 19min 22s\nWall time: 8min 13s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=45, max_features=30, min_samples_leaf=200,\n",
       "                       n_estimators=500, n_jobs=-1)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "%%time \n",
    "rf.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Roc Auc Score: 0.6141971463346385\n"
     ]
    }
   ],
   "source": [
    "print(\"Roc Auc Score:\", roc_auc_score(y_test_split, rf.predict(X_test_split)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}